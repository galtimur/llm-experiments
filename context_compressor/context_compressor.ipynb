{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "dtype = torch.bfloat16"
   ],
   "id": "27afdea5a0fd16bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_name = 'princeton-nlp/Sheared-LLaMA-1.3B'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=dtype).to(device)\n",
    "# config = AutoConfig.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_config(config, torch_dtype=dtype).to(device)\n",
    "# pretrained_model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=dtype).to(device)\n",
    "# model.lm_head.load_state_dict(pretrained_model.lm_head.state_dict())\n",
    "# model.model.embed_tokens.load_state_dict(pretrained_model.model.embed_tokens.state_dict())\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "98dfe16859f6069c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "max_tokens = 1024\n",
    "text_path = \"/mnt/data/galimzyanov/datasets/ulysses.txt\"\n",
    "with open(text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "token_ids = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "token_ids = token_ids[:,:max_tokens]\n",
    "print(f\"Number of tokens = {token_ids.shape[1]}\")"
   ],
   "id": "afed2d9695fa849"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr = 1e-1\n",
    "\n",
    "batch_size = len(token_ids)\n",
    "# prefix = torch.randn(batch_size, 1, model.config.hidden_size, device=device, requires_grad=True, dtype=dtype)\n",
    "bos_token_id = torch.tensor(tokenizer.convert_tokens_to_ids(tokenizer.special_tokens_map['bos_token']), device=device)\n",
    "bos_emb = model.model.embed_tokens(bos_token_id)\n",
    "prefix = bos_emb.view(1, 1, -1).repeat(batch_size, 1, 1).detach().clone().requires_grad_(True)\n",
    "opt = torch.optim.Adam([prefix], lr)\n",
    "# opt = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "for param in model.parameters():\n",
    "    assert not param.requires_grad, \"Model parameters are not frozen!\""
   ],
   "id": "adb3188b4a894bba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_steps = 5120\n",
    "max_acc = 0\n",
    "# pbar = tqdm(total=num_steps, desc=\"Training Progress\", unit=\"step\")\n",
    "for step in tqdm(range(num_steps)):\n",
    "    opt.zero_grad()\n",
    "    tok_embs = model.model.embed_tokens(token_ids)\n",
    "\n",
    "    embs = torch.cat([prefix, tok_embs], 1)\n",
    "    outputs = model(inputs_embeds=embs)\n",
    "    logits = outputs.logits\n",
    "    # loss = torch.sum(logits)\n",
    "    logits = logits[:, 1:-1]\n",
    "    target_tokens = token_ids[:, 1:]\n",
    "    predicted_tokens = torch.argmax(logits, dim=-1)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.reshape(-1, logits.shape[-1]),\n",
    "                                             target_tokens.reshape(-1))\n",
    "    correct_predictions = (predicted_tokens == target_tokens).float()\n",
    "    accuracy = correct_predictions.sum() / correct_predictions.numel()\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if step%50 == 0:\n",
    "        print(f'Step = {step}, Loss = {loss.item():.2f}, Accuracy = {accuracy:.2f}')\n",
    "    # pbar.set_postfix({\"loss\": loss.item()})\n",
    "    # pbar.update(1)\n",
    "    if accuracy > max_acc:\n",
    "        max_acc = accuracy\n",
    "print(f\"Max accuracy = {max_acc:.2f}\")"
   ],
   "id": "e438c3b99bbe236f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc988f2ce1d795c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# outputs\n",
    "# model.model.embed_tokens(token_ids)\n",
    "\n",
    "# model.model.embed_tokens.weight.isnan().any(1).sum()\n"
   ],
   "id": "a25d0800f0886327"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model",
   "id": "5e1aa8ba56e4c047"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "efa8e572daad3bdd"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
