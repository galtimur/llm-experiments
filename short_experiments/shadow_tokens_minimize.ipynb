{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T09:46:45.060717Z",
     "start_time": "2025-03-31T09:46:40.896034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from emb_vectors_functions import find_self_embeds, get_shadow_ratios\n",
    "from model_loading import get_weight_by_name\n",
    "from find_bed_embed_min import train_vectors, batch_list"
   ],
   "id": "c8a4c2d3a58c68cd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:55:31.664198Z",
     "start_time": "2025-03-29T11:55:30.533842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \"meta-llama/Llama-3.1-70B\", \"meta-llama/Llama-3.1-8B\"\n",
    "# \"Qwen/Qwen2.5-0.5B-Instruct\", \"Qwen/Qwen2.5-1.5B-Instruct\", \"Qwen/Qwen2.5-3B-Instruct\", \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "# \"Qwen/Qwen2.5-14B-Instruct\", \"Qwen/Qwen2.5-32B-Instruct\", \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "model_name = \"meta-llama/Llama-3.1-70B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "embeddings = get_weight_by_name(model_name, \"head\")\n",
    "embeddings = embeddings.cuda()\n",
    "# embeddings = torch.randn_like(embeddings)\n",
    "embeddings.requires_grad = False"
   ],
   "id": "a2224e6661df7de4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fetching 50 files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebf996a79a0c4475bd9951fe8fca7bef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:55:36.867275Z",
     "start_time": "2025-03-29T11:55:33.839058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fail_indices, failed_res_emb, failed_pairs = find_self_embeds(embeddings, tokenizer)\n",
    "print(f\"Number of bad embeddings = {len(fail_indices)}\")"
   ],
   "id": "35320c67765020f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad embeddings = 1060\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:55:39.728508Z",
     "start_time": "2025-03-29T11:55:39.725805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shadow_ratios = get_shadow_ratios(fail_indices, embeddings)\n",
    "# shadow_ratios_sorted = sorted(shadow_ratios, key=lambda x: x[1], reverse=True);"
   ],
   "id": "e8946f32374c8154",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:55:39.947334Z",
     "start_time": "2025-03-29T11:55:39.944110Z"
    }
   },
   "cell_type": "code",
   "source": "# loss, x_optim, self_emb, mask, bad_indices = train_vectors(n_lst, embeddings, n_steps=100, verbose=True)",
   "id": "7e0ac16307e2f75c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:55:45.589008Z",
     "start_time": "2025-03-29T11:55:45.585577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ind_batched_list = batch_list(fail_indices, 1000)\n",
    "# ind_batched_list = [[183]]"
   ],
   "id": "c609f03ce834233f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:56:50.140721Z",
     "start_time": "2025-03-29T11:55:46.319155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Number of bad embeddings = {len(fail_indices)}, dimension = {embeddings.shape[1]}, dict size = {embeddings.shape[0]}\"\n",
    ")\n",
    "\n",
    "for ind_list_ in ind_batched_list:\n",
    "    x_optim = None\n",
    "    ind_list = ind_list_\n",
    "    pbar = tqdm(range(300))\n",
    "    for i in pbar:\n",
    "        loss, x_optim, self_emb, mask, is_good_embed = train_vectors(\n",
    "            ind_list,\n",
    "            embeddings,\n",
    "            x_optim_start=x_optim,\n",
    "            n_steps=200,\n",
    "            verbose=False,\n",
    "            use_tqdm=False,\n",
    "        )\n",
    "        ind_list = np.array(ind_list)[~is_good_embed]\n",
    "        x_optim = x_optim[~is_good_embed]\n",
    "        pbar.set_postfix_str(f\"Bad embeds: {len(ind_list)}/{len(ind_list_)}\")\n",
    "\n",
    "        if len(ind_list) == 0:\n",
    "            break"
   ],
   "id": "6ada7969a4043995",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad embeddings = 1060, dimension = 8192, dict size = 128256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 29/300 [00:44<06:56,  1.54s/it, Bad embeds: 0/1000] \n",
      "  5%|▌         | 16/300 [00:19<05:42,  1.21s/it, Bad embeds: 0/60] \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T17:33:44.097777Z",
     "start_time": "2025-03-22T17:28:18.577576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m = 30000\n",
    "d = embeddings.shape[1]\n",
    "num_iterations = 1000\n",
    "argmax_results = []\n",
    "\n",
    "for iteration in tqdm(range(num_iterations)):\n",
    "    X = torch.randn(m, d, device=\"cuda\", dtype=torch.bfloat16, requires_grad=False)\n",
    "    X = X / torch.norm(X, dim=1, keepdim=True)\n",
    "    logits = X @ embeddings.T  # (m, n)\n",
    "    argmax_indices = logits.argmax(dim=1)  # (m,)\n",
    "    argmax_results.append(argmax_indices.cpu())\n",
    "    del X, logits\n",
    "    torch.cuda.empty_cache()\n",
    "    # gc.collect()\n",
    "\n",
    "argmax_results = torch.cat(argmax_results)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "id": "267236dd01d5db5b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:25<00:00,  3.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "751"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T17:33:45.336328Z",
     "start_time": "2025-03-22T17:33:44.163760Z"
    }
   },
   "cell_type": "code",
   "source": "unique_indices, counts = torch.unique(argmax_results, return_counts=True)",
   "id": "509c90892cf1063b",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sorted_counts, sorted_idx = counts.sort(descending=True)\n",
    "sorted_indices = unique_indices[sorted_idx]"
   ],
   "id": "19293a17b80b24b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
