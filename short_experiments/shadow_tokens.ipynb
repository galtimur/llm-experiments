{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:44:46.469409Z",
     "start_time": "2025-03-18T15:44:42.962994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# from torch.linalg import svd\n",
    "from torch.linalg import svd\n",
    "\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from emb_vectors_functions import (\n",
    "    find_self_embeds,\n",
    "    get_model_and_embed,\n",
    "    get_shadow_ratios,\n",
    ")"
   ],
   "id": "c8a4c2d3a58c68cd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:44:50.704293Z",
     "start_time": "2025-03-18T15:44:47.650271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"  # \"meta-llama/Meta-Llama-3.1-8B\"  # \"meta-llama/Meta-Llama-3.1-8B\" , \"gpt2\", \"meta-llama/Llama-2-7b-hf\"\n",
    "model, embedding, head, model_norm, mean_norm, tokenizer = get_model_and_embed(\n",
    "    model_name\n",
    ")\n",
    "\n",
    "del model, embedding\n",
    "embeddings = head\n",
    "embeddings.requires_grad = False"
   ],
   "id": "d4805a55975d91ef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:44:57.372739Z",
     "start_time": "2025-03-18T15:44:54.684016Z"
    }
   },
   "cell_type": "code",
   "source": "fail_indices, failed_res_emb, failed_pairs = find_self_embeds(embeddings, tokenizer)",
   "id": "35320c67765020f1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  6.26it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T15:45:26.043659Z",
     "start_time": "2025-03-18T15:45:25.243208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "shadow_ratios = get_shadow_ratios(fail_indices, embeddings)\n",
    "shadow_ratios_sorted = sorted(shadow_ratios, key=lambda x: x[1], reverse=True);"
   ],
   "id": "e8946f32374c8154",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T08:46:04.924815Z",
     "start_time": "2025-03-18T08:46:04.590995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = 177\n",
    "embeddings_cut = embeddings  # embeddings[:10000]\n",
    "embeddings_others = torch.cat((embeddings_cut[:n], embeddings_cut[n + 1 :]), dim=0)\n",
    "self_emb = embeddings_cut[n]\n",
    "\n",
    "A = self_emb - embeddings_others\n",
    "A.requires_grad = False\n",
    "torch.all(A @ self_emb > 0)\n",
    "\n",
    "# embeddings_others = embeddings_others.detach().cpu()\n",
    "# self_emb = self_embed.detach().cpu()\n",
    "# A = A.detach().cpu()"
   ],
   "id": "625b514938fed3e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T08:46:05.069918Z",
     "start_time": "2025-03-18T08:46:05.066701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = self_emb.detach().clone()\n",
    "x.requires_grad = True\n",
    "optimizer = torch.optim.SGD([x], lr=0.01)\n",
    "optimizer = torch.optim.AdamW([x], lr=0.01)"
   ],
   "id": "1e8e946fd90a9be5",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-18T08:49:40.009677Z",
     "start_time": "2025-03-18T08:46:05.776962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epsilon = 1e-4\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss = torch.sum(relu(-A @ x + epsilon))\n",
    "    print(f\"Initial loss = {loss}\")\n",
    "\n",
    "for step in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    loss = torch.sum(relu(-A @ x + epsilon))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (step + 1) % 10 == 0:\n",
    "        print(f\"Step {step+1}, Loss: {loss.item()}\")\n",
    "    if loss.item() <= 0:\n",
    "        break\n",
    "\n",
    "print(\"Optimization finished. Final x:\", loss.item())\n",
    "print(f\"Target embedding - {torch.all(A@x>0).item()}, min = {torch.min(A@x)}\")"
   ],
   "id": "5121d00a62606561",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss = 6.931521415710449\n",
      "Step 10, Loss: 0.030173495411872864\n",
      "Step 20, Loss: 0.02480473183095455\n",
      "Step 30, Loss: 0.017095521092414856\n",
      "Step 40, Loss: 0.009619321674108505\n",
      "Step 50, Loss: 0.004163955803960562\n",
      "Step 60, Loss: 0.0018103988841176033\n",
      "Step 70, Loss: 0.0009649852872826159\n",
      "Step 80, Loss: 0.0005561368889175355\n",
      "Step 90, Loss: 0.00037754763616248965\n",
      "Step 100, Loss: 0.0003059612645301968\n",
      "Step 110, Loss: 0.0002523293369449675\n",
      "Step 120, Loss: 0.0002088374167215079\n",
      "Step 130, Loss: 0.0001777974102878943\n",
      "Step 140, Loss: 0.00015200275811366737\n",
      "Step 150, Loss: 0.00013408041559159756\n",
      "Step 160, Loss: 0.00012149220128776506\n",
      "Step 170, Loss: 0.00010237032256554812\n",
      "Step 180, Loss: 8.380766666959971e-05\n",
      "Step 190, Loss: 6.539615424117073e-05\n",
      "Step 200, Loss: 5.5209893616847694e-05\n",
      "Step 210, Loss: 5.110912024974823e-05\n",
      "Step 220, Loss: 4.761807213071734e-05\n",
      "Step 230, Loss: 4.4579523091670126e-05\n",
      "Step 240, Loss: 4.1886385588441044e-05\n",
      "Step 250, Loss: 3.971511614508927e-05\n",
      "Step 260, Loss: 3.761104017030448e-05\n",
      "Step 270, Loss: 3.54997391696088e-05\n",
      "Step 280, Loss: 3.335514338687062e-05\n",
      "Step 290, Loss: 3.233054303564131e-05\n",
      "Step 300, Loss: 3.15458164550364e-05\n",
      "Step 310, Loss: 3.082215698668733e-05\n",
      "Step 320, Loss: 3.0110342777334154e-05\n",
      "Step 330, Loss: 2.939290425274521e-05\n",
      "Step 340, Loss: 2.866381692001596e-05\n",
      "Step 350, Loss: 2.792093437165022e-05\n",
      "Step 360, Loss: 2.716362359933555e-05\n",
      "Step 370, Loss: 2.6391688152216375e-05\n",
      "Step 380, Loss: 2.5605171686038375e-05\n",
      "Step 390, Loss: 2.4804117856547236e-05\n",
      "Step 400, Loss: 2.3988672182895243e-05\n",
      "Step 410, Loss: 2.3158849216997623e-05\n",
      "Step 420, Loss: 2.2314830857794732e-05\n",
      "Step 430, Loss: 2.1456595277413726e-05\n",
      "Step 440, Loss: 2.0584295270964503e-05\n",
      "Step 450, Loss: 1.9697996322065592e-05\n",
      "Step 460, Loss: 1.879774936242029e-05\n",
      "Step 470, Loss: 1.788364170351997e-05\n",
      "Step 480, Loss: 1.731007796479389e-05\n",
      "Step 490, Loss: 1.6872210835572332e-05\n",
      "Step 500, Loss: 1.644613075768575e-05\n",
      "Step 510, Loss: 1.6020356270018965e-05\n",
      "Step 520, Loss: 1.559084194013849e-05\n",
      "Step 530, Loss: 1.51561907841824e-05\n",
      "Step 540, Loss: 1.471588620916009e-05\n",
      "Step 550, Loss: 1.4269804523792118e-05\n",
      "Step 560, Loss: 1.3817865692544729e-05\n",
      "Step 570, Loss: 1.3360098819248378e-05\n",
      "Step 580, Loss: 1.2896482076030225e-05\n",
      "Step 590, Loss: 1.2427030014805496e-05\n",
      "Step 600, Loss: 1.1951764463447034e-05\n",
      "Step 610, Loss: 1.1470721801742911e-05\n",
      "Step 620, Loss: 1.0983880201820284e-05\n",
      "Step 630, Loss: 1.0491246939636767e-05\n",
      "Step 640, Loss: 9.992851119022816e-06\n",
      "Step 650, Loss: 9.488714567851275e-06\n",
      "Step 660, Loss: 8.978822734206915e-06\n",
      "Step 670, Loss: 8.46318289404735e-06\n",
      "Step 680, Loss: 7.941802323330194e-06\n",
      "Step 690, Loss: 2.686255902517587e-05\n",
      "Step 700, Loss: 6.679067882942036e-05\n",
      "Step 710, Loss: 1.762465399224311e-05\n",
      "Step 720, Loss: 1.716683618724346e-05\n",
      "Step 730, Loss: 1.6176469216588885e-05\n",
      "Step 740, Loss: 1.4986748283263296e-05\n",
      "Step 750, Loss: 1.3718468835577369e-05\n",
      "Step 760, Loss: 1.2414195225574076e-05\n",
      "Step 770, Loss: 1.1088894098065794e-05\n",
      "Step 780, Loss: 9.747898729983717e-06\n",
      "Step 790, Loss: 8.39300628285855e-06\n",
      "Step 800, Loss: 7.150927558541298e-06\n",
      "Step 810, Loss: 6.480375304818153e-06\n",
      "Step 820, Loss: 5.851012247148901e-06\n",
      "Step 830, Loss: 5.23246853845194e-06\n",
      "Step 840, Loss: 4.614070348907262e-06\n",
      "Step 850, Loss: 3.992048732470721e-06\n",
      "Step 860, Loss: 3.3650867408141494e-06\n",
      "Step 870, Loss: 2.732704160735011e-06\n",
      "Step 880, Loss: 2.0947481971234083e-06\n",
      "Step 890, Loss: 1.4511533663608134e-06\n",
      "Step 900, Loss: 8.018614607863128e-07\n",
      "Step 910, Loss: 1.469306880608201e-07\n",
      "Optimization finished. Final x: 0.0\n",
      "Target embedding - True, min = 0.00010010904225055128\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8bbf5d845ff6c6dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:57:52.884206Z",
     "start_time": "2025-03-17T20:57:52.881112Z"
    }
   },
   "cell_type": "code",
   "source": "from scipy.optimize import linprog",
   "id": "452b400be54728ae",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-17T20:59:30.169269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n, d = A.shape  # A is (n, d), x is (n,)\n",
    "epsilon = 1e-6\n",
    "\n",
    "c = np.zeros(d)  # No objective function, just feasibility\n",
    "bounds = [(None, None)] * d  # x can take any value\n",
    "\n",
    "res = linprog(c, A_ub=-A, b_ub=-epsilon * np.ones(n), bounds=bounds, method=\"highs\")"
   ],
   "id": "38853639399f3cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cc57ca631a01cc51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f8854fb64ce3c076"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T16:06:30.928470Z",
     "start_time": "2025-03-17T16:06:30.925433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from numpy.linalg import svd\n",
    "# from scipy.linalg import svd\n",
    "from torch.linalg import svd"
   ],
   "id": "5d8f8017a2fe9912",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T16:59:52.678531Z",
     "start_time": "2025-03-17T16:59:42.803147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# U, S, Vt = svd(A.T, full_matrices=True)\n",
    "U, S, Vt = svd(A.T)"
   ],
   "id": "355aab1731cb8688",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T17:00:01.968727Z",
     "start_time": "2025-03-17T17:00:01.946994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Null space basis vectors correspond to zero singular values\n",
    "tol = 1e-10  # Tolerance to detect numerical zeros\n",
    "null_space = Vt[S < tol]  # Extract null space basis"
   ],
   "id": "e4246d39e0c00517",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [2048] at index 0 does not match the shape of the indexed tensor [9999, 9999] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Null space basis vectors correspond to zero singular values\u001b[39;00m\n\u001b[32m      2\u001b[39m tol = \u001b[32m1e-10\u001b[39m  \u001b[38;5;66;03m# Tolerance to detect numerical zeros\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m null_space = \u001b[43mVt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mS\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# Extract null space basis\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: The shape of the mask [2048] at index 0 does not match the shape of the indexed tensor [9999, 9999] at index 0"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T17:00:24.372036Z",
     "start_time": "2025-03-17T17:00:16.459237Z"
    }
   },
   "cell_type": "code",
   "source": "torch.linalg.matrix_rank(A.T)",
   "id": "cebf25a7c29e05dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2048)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T19:52:27.435156Z",
     "start_time": "2025-03-17T19:52:27.431088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog"
   ],
   "id": "aced2e938dd50719",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T20:07:30.661664Z",
     "start_time": "2025-03-17T20:06:01.046869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d, n = A.T.shape\n",
    "epsilon = 1e-6\n",
    "\n",
    "c = np.zeros(n)\n",
    "bounds = [(epsilon, None)] * n  # Enforce strict positivity (x_i > epsilon)\n",
    "res = linprog(c, A_eq=A.T, b_eq=np.zeros(d), bounds=bounds, method=\"highs\")"
   ],
   "id": "79983c1856295dab",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T19:55:41.926560Z",
     "start_time": "2025-03-17T19:55:41.922786Z"
    }
   },
   "cell_type": "code",
   "source": "qq = res",
   "id": "2b758e405e077e1d",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T19:58:43.491111Z",
     "start_time": "2025-03-17T19:58:43.487778Z"
    }
   },
   "cell_type": "code",
   "source": "res",
   "id": "a6a35ce825d2b69d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       message: The problem is infeasible. (HiGHS Status 8: model_status is Infeasible; primal_status is Infeasible)\n",
       "       success: False\n",
       "        status: 2\n",
       "           fun: None\n",
       "             x: None\n",
       "           nit: 69\n",
       "         lower:  residual: None\n",
       "                marginals: None\n",
       "         upper:  residual: None\n",
       "                marginals: None\n",
       "         eqlin:  residual: None\n",
       "                marginals: None\n",
       "       ineqlin:  residual: None\n",
       "                marginals: None"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b41f3d5aaae134b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
